{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# gensim modules\n",
    "from gensim import utils\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# numpy\n",
    "import numpy\n",
    "\n",
    "# classifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, sources):\n",
    "        self.sources = sources\n",
    "        \n",
    "        flipped = {}\n",
    "        \n",
    "        # make sure that keys are unique\n",
    "        for key, value in sources.items():\n",
    "            if value not in flipped:\n",
    "                flipped[value] = [key]\n",
    "            else:\n",
    "                raise Exception('Non-unique prefix encountered')\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    yield LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no])\n",
    "    \n",
    "    def to_array(self):\n",
    "        self.sentences = []\n",
    "        for source, prefix in self.sources.items():\n",
    "            with utils.smart_open(source) as fin:\n",
    "                for item_no, line in enumerate(fin):\n",
    "                    self.sentences.append(LabeledSentence(utils.to_unicode(line).split(), [prefix + '_%s' % item_no]))\n",
    "        return self.sentences\n",
    "    \n",
    "    def sentences_perm(self):\n",
    "        return numpy.random.permutation(self.sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#note that at this doc2vec stage, the model is not doing classification, it's simply training a doc2vec model for each\n",
    "#sentence, it doesn' t need to know which class these belong to. Only after we trained it and then we train a classifier\n",
    "# then we need to access the train_pos or train_neg or whatever class you have, in which case we can access them via\n",
    "#their special prefix TRAIN_NEG_1, etc. These are two distinct stages.\n",
    "\n",
    "#sources = {'test-neg.txt':'TEST_NEG', 'test-pos.txt':'TEST_POS', 'train-neg.txt':'TRAIN_NEG', 'train-pos.txt':'TRAIN_POS', 'train-unsup.txt':'TRAIN_UNS'}\n",
    "\n",
    "# we will need to divide these data into train and test\n",
    "sources = {'manban_all_test.txt':'TEST_MB', 'manban_all_train.txt':'TRAIN_MB','kuaiban_all_test.txt':'TEST_KB','kuaiban_all_train.txt':'TRAIN_KB','yaoban_all_test.txt':'TEST_YAB','yaoban_all_train.txt':'TRAIN_YAB','yuanban_all_test.txt':'TEST_YB','yuanban_all_train.txt':'TRAIN_YB'}\n",
    "sentences = LabeledLineSentence(sources)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sary=sentences.to_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Desktop/ISMIR17/doc2vec_shuo/plbs\n"
     ]
    }
   ],
   "source": [
    "cd plbs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在\n",
      "此\n",
      "金殿\n",
      "用\n",
      "目睁\n",
      "倒\n",
      "叫\n",
      "某\n",
      "家\n",
      "喜\n",
      "心中\n",
      "我\n",
      "今\n",
      "不\n",
      "打\n",
      "万历主\n",
      "只怕\n",
      "江山\n",
      "不太\n",
      "平\n",
      "我\n",
      "把\n",
      "铜锤\n",
      "拿\n",
      "在手\n",
      "我\n",
      "今\n",
      "要\n",
      "打主\n",
      "圣龙\n",
      "一\n",
      "见\n",
      "孙安绑\n",
      "下殿\n",
      "好不叫人\n",
      "心痛酸\n",
      "职都\n",
      "押\n",
      "在\n",
      "龙\n",
      "书案\n",
      "收心\n",
      "务本\n",
      "种\n",
      "庄田\n",
      "一\n",
      "见\n",
      "千\n",
      "岁\n",
      "下\n",
      "金殿\n",
      "倒\n",
      "叫\n",
      "杨溥泪\n",
      "不\n",
      "干\n",
      "职\n",
      "都\n",
      "押\n",
      "在\n",
      "龙\n",
      "书案\n",
      "山西\n",
      "蒲州\n",
      "快乐\n",
      "安然\n",
      "众位\n",
      "大人\n",
      "下\n",
      "金殿\n",
      "倒\n",
      "叫\n",
      "下官\n",
      "不\n",
      "耐烦\n",
      "职都\n",
      "押\n",
      "在\n",
      "龙\n",
      "书案\n",
      "收心\n",
      "务本\n",
      "不\n",
      "居\n",
      "官\n",
      "众位\n",
      "大人\n",
      "把\n",
      "殿下\n",
      "倒叫杨\n",
      "太\n",
      "泪\n",
      "汪汪\n",
      "在\n",
      "金殿\n",
      "满\n",
      "朝\n",
      "文武\n",
      "俱\n",
      "下殿\n",
      "留\n",
      "我\n",
      "一\n",
      "人保\n",
      "江山\n"
     ]
    }
   ],
   "source": [
    "for i in sary[0][0]:print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec(min_count=1, window=10, size=100, sample=1e-4, negative=5, workers=7)\n",
    "\n",
    "model.build_vocab(sentences.to_array())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('./jingju.d2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "伤心\n",
      "0.96675914526\n",
      "气丧\n",
      "0.962376117706\n",
      "由人\n",
      "0.960183501244\n",
      "垂掉\n",
      "0.95185571909\n",
      "陈炳顺\n",
      "0.95154863596\n",
      "陵寝\n",
      "0.95066344738\n",
      "落泪儿\n",
      "0.949612498283\n",
      "五内如焚\n",
      "0.941762208939\n",
      "牢骚\n",
      "0.941731333733\n",
      "白如银\n",
      "0.939425051212\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "s=model.most_similar(codecs.decode('悲伤','utf-8'))\n",
    "for i in s: \n",
    "    for j in i:\n",
    "        print j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## disclaimer\n",
    "\n",
    "even though these sentiment word don't make sense, remember, we didn't train these vectors based on sentiment class labels. we trained on banshi labels. therefore, the real question is whether words in the same banshi come together, which we have no intuition about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02341812,  0.5366019 , -0.24876203, -0.20512319,  0.01443002,\n",
       "       -0.37027919,  0.07008942,  0.63358134,  0.13886771, -0.19116218,\n",
       "        0.20827897,  0.0724121 , -0.20983098, -0.12775764,  0.10004643,\n",
       "       -0.07850786, -0.05763858, -0.2642684 , -0.3929947 ,  0.1294845 ,\n",
       "       -0.28692403,  0.26159072, -0.20410521,  0.57262319, -0.01929191,\n",
       "        0.34114429, -0.12959751,  0.54861474,  0.14315757, -0.05447926,\n",
       "       -0.15363109,  0.37652737, -0.33509755,  0.52424955,  0.00793828,\n",
       "        0.46900639,  0.21108279,  0.09353911,  0.64020413, -0.20744608,\n",
       "       -0.34293309, -0.94957787,  0.56172746, -0.60609156,  0.3805725 ,\n",
       "        0.42465335,  0.50341278, -0.02044366, -1.02513921,  0.43874472,\n",
       "       -0.35291159, -0.2463025 , -0.2448426 , -0.78223664, -0.02623495,\n",
       "        0.10846089,  0.37997806,  0.32956275, -0.03049704,  0.17964257,\n",
       "        0.44880497, -0.33024496, -0.19095866,  0.5198248 , -0.11150498,\n",
       "        0.6178382 ,  0.64241058,  0.58021307,  0.12484313, -0.14633805,\n",
       "        0.37477621, -0.1393901 ,  0.13937907, -0.25248215,  0.39717677,\n",
       "       -0.26134607,  0.16332296,  0.16269299,  0.34004727,  0.32151788,\n",
       "       -0.19855605, -0.24158333, -0.41958031,  0.3481676 , -0.08234924,\n",
       "       -0.13524753,  0.26025137,  0.36849177, -0.66661191,  0.35370135,\n",
       "        0.38967237,  0.47726962,  0.54422438, -0.17451252, -0.27089006,\n",
       "        0.0985113 , -0.19685784,  0.24953565, -0.89708841,  0.59822124], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs['TEST_MB_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating data for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is really about creating a 2d array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "def count_num_lines(file_name):\n",
    "    f=open(file_name,'r').read()\n",
    "    return len([i for i in f if i=='\\n'])\n",
    "\n",
    "\n",
    "\n",
    "def build_train_data(sources):\n",
    "    \"\"\"build data 2d array using doc2vec repr for classification, and labels, for training and testing\"\"\"\n",
    "    #for each document, loop through the lines, and append the doc2vec representation of each line into the output data file.\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    classes=['MB','KB','YAB','YB']\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    for k in sources.keys():\n",
    "        #print k\n",
    "        #training data only, four sets\n",
    "        if 'train' not in k:\n",
    "            continue\n",
    "        print k\n",
    "        size = count_num_lines(k)\n",
    "        print 'size:',size\n",
    "        prefix=sources[k]\n",
    "        for i in range(size):\n",
    "            lab=[j for j in classes if j in prefix][0]\n",
    "            #print 'label:',lab\n",
    "            prefix_train = prefix + \"_\" + str(i)\n",
    "            data.append(model.docvecs[prefix_train])\n",
    "            labels.append(lab) #this is nominal label, later to be transformed\n",
    "    data=np.array(data)\n",
    "    labels=le.transform(labels)\n",
    "    return data,labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sources = {'manban_all_test.txt':'TEST_MB', 'manban_all_train.txt':'TRAIN_MB','kuaiban_all_test.txt':'TEST_KB','kuaiban_all_train.txt':'TRAIN_KB','yaoban_all_test.txt':'TEST_YAB','yaoban_all_train.txt':'TRAIN_YAB','yuanban_all_test.txt':'TEST_YB','yuanban_all_train.txt':'TRAIN_YB'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yuanban_all_train.txt\n",
      "size: 335\n",
      "manban_all_train.txt\n",
      "size: 174\n",
      "kuaiban_all_train.txt\n",
      "size: 210\n",
      "yaoban_all_train.txt\n",
      "size: 405\n"
     ]
    }
   ],
   "source": [
    "data,labels=build_train_data(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04494349,  0.06091836,  0.01283445, ...,  0.1158127 ,\n",
       "        -0.21338543,  0.15746288],\n",
       "       [ 0.14202277,  0.53619534, -0.29973727, ..., -0.0308947 ,\n",
       "        -0.90494668,  0.75839096],\n",
       "       [ 0.0028049 ,  0.45299432,  0.11641489, ...,  0.0364399 ,\n",
       "        -1.23158395,  0.63742286],\n",
       "       ..., \n",
       "       [ 0.27983087,  0.92724085,  0.19805695, ..., -0.32091567,\n",
       "        -1.18062317,  0.99392557],\n",
       "       [ 0.03852019,  0.78996921, -0.22482361, ...,  0.42976123,\n",
       "        -1.08289778,  0.73219556],\n",
       "       [-0.00581133,  0.67735714, -0.22459288, ...,  0.29841894,\n",
       "        -0.90452051,  0.56273407]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_test_data(sources):\n",
    "    \"\"\"build data 2d array using doc2vec repr for classification, and labels, for training and testing\"\"\"\n",
    "    #for each document, loop through the lines, and append the doc2vec representation of each line into the output data file.\n",
    "    data=[]\n",
    "    labels=[]\n",
    "    classes=['MB','KB','YAB','YB']\n",
    "    \n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(classes)\n",
    "    for k in sources.keys():\n",
    "        #print k\n",
    "        #training data only, four sets\n",
    "        if 'test' not in k:\n",
    "            continue\n",
    "        print k\n",
    "        size = count_num_lines(k)\n",
    "        print 'size:',size\n",
    "        prefix=sources[k]\n",
    "        for i in range(size):\n",
    "            lab=[j for j in classes if j in prefix][0]\n",
    "            #print 'label:',lab\n",
    "            prefix_test = prefix + \"_\" + str(i)\n",
    "            data.append(model.docvecs[prefix_test])\n",
    "            labels.append(lab) #this is nominal label, later to be transformed\n",
    "    data=np.array(data)\n",
    "    labels=le.transform(labels)\n",
    "    return data,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yaoban_all_test.txt\n",
      "size: 44\n",
      "kuaiban_all_test.txt\n",
      "size: 23\n",
      "yuanban_all_test.txt\n",
      "size: 37\n",
      "manban_all_test.txt\n",
      "size: 19\n"
     ]
    }
   ],
   "source": [
    "test_data,test_labs=build_test_data(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "print len(test_data)\n",
    "print len(test_labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Desktop/ISMIR17/doc2vec_shuo\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zangsir/Desktop/ISMIR17/doc2vec_shuo/plsqbs\n"
     ]
    }
   ],
   "source": [
    "cd plsqbs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ehmb_all_train.txt     xpkb_all_train.txt     xpyuanb_all_train.txt\r\n",
      "ehyaob_all_train.txt   xpmb_all_train.txt\r\n",
      "ehyuanb_all_train.txt  xpyaob_all_train.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls *train.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=\"\"\"ehmb_all_test.txt     xpkb_all_test.txt     xpyuanb_all_test.txt\n",
    "ehyaob_all_test.txt   xpmb_all_test.txt\n",
    "ehyuanb_all_test.txt  xpyaob_all_test.txt\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=a.replace('\\n',' ')\n",
    "b=a.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa=\"\"\"ehmb_all_train.txt     xpkb_all_train.txt     xpyuanb_all_train.txt\n",
    "ehyaob_all_train.txt   xpmb_all_train.txt\n",
    "ehyuanb_all_train.txt  xpyaob_all_train.txt\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa=aa.replace('\\n',' ')\n",
    "bb=aa.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'ehmb_all_train.txt':'TRAIN_', 'xpkb_all_train.txt':'TRAIN_', 'xpyuanb_all_train.txt':'TRAIN_', 'ehyaob_all_train.txt':'TRAIN_', 'xpmb_all_train.txt':'TRAIN_', 'ehyuanb_all_train.txt':'TRAIN_', 'xpyaob_all_train.txt':'TRAIN_',\n"
     ]
    }
   ],
   "source": [
    "for i in bb:\n",
    "    if i!='':\n",
    "        print \"'\" + i + \"'\"+\":'TRAIN_',\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d={'ehmb_all_test.txt':'TEST_EHMB', 'xpkb_all_test.txt':'TEST_XPKB', 'xpyuanb_all_test.txt':'TEST_XPYB', 'ehyaob_all_test.txt':'TEST_EHYAB', 'xpmb_all_test.txt':'TEST_XPMB', 'ehyuanb_all_test.txt':'TEST_EHYB', 'xpyaob_all_test.txt':'TEST_XPYAB','ehmb_all_train.txt':'TRAIN_EHMB', 'xpkb_all_train.txt':'TRAIN_XPKB', 'xpyuanb_all_train.txt':'TRAIN_XPYB', 'ehyaob_all_train.txt':'TRAIN_EHYAB', 'xpmb_all_train.txt':'TRAIN_XPMB', 'ehyuanb_all_train.txt':'TRAIN_EHYB', 'xpyaob_all_train.txt':'TRAIN_XPYAB'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52774999999999994"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf=[0.6,0.55,0.48,0.48,0.616,0.536,0.472,0.488]\n",
    "np.mean(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.799999999999997"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([39,36,40,45,44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
